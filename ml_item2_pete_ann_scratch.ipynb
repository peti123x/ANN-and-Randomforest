{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ended after  299  iterations. Last output:\n",
      "[[0.99897356]]\n",
      "Finished in  0:00:00.031214\n",
      "Running prediction on input array\n",
      "Predicted for this input\n",
      "[[0.9989736]]\n",
      "Real output\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt \n",
    "import pandas\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "#Read coordinate csv. Col 1 is x coords and Col2 is y coords. \n",
    "def read_coords(filename):     \n",
    "    myFile = open(filename) \n",
    "    row =0 \n",
    "    coords =[] \n",
    "    for line in myFile:\n",
    "        #skip first line as it contains labels\n",
    "        if row > 0:\n",
    "            coords.append(line.rstrip().split(\",\")[:])\n",
    "        row = row+1\n",
    "        #coords[row] = line.rstrip().split(\",\")[:] \n",
    "    myFile.close()\n",
    "    return coords\n",
    "\n",
    "def normalise(data):\n",
    "    #Transpose, take out labels and convert remaining data to float\n",
    "    data = data.transpose()\n",
    "    label = data[0]\n",
    "    data = data[1:]\n",
    "    data = data.astype(float)\n",
    "    #Enumerate through each col then each point in all\n",
    "    #Do z = (xi - min(x))/(max(x)-min(x)) to normalise where x marks the set of numbers\n",
    "    for j, col in enumerate(data):\n",
    "        #Get min and max to be able to normalise\n",
    "        cMax = np.amax(col)\n",
    "        cMin = np.amin(col)\n",
    "        for i, x in enumerate(col):\n",
    "            norm = (x - cMin)/(cMax - cMin)\n",
    "            #Write back\n",
    "            data[j][i] = norm\n",
    "    #Construct mutated data into original array with labels that we do by\n",
    "    #creating new list, adding labels and the dataset, converting to np array then transposing back to original dim\n",
    "    newData = []\n",
    "    newData.append(label)\n",
    "    newData[1:] = data\n",
    "    newData = np.asarray(newData)\n",
    "    newData = newData.transpose()\n",
    "    return newData\n",
    "\n",
    "def summarise(data):\n",
    "    print(\"This set has a dimension of \" , data.shape)\n",
    "    #This will contain a series of tuples that charectarise each row\n",
    "    summary = []\n",
    "    cols = ['Power_range_sensor_1', 'Power_range_sensor_2', 'Power_range_sensor_3', 'Power_range_sensor_4', 'Pressure_sensor_1', 'Pressure_sensor_2','Pressure_sensor_3', 'Pressure_sensor_4', 'Vibration_sensor_1', 'Vibration_sensor_2', 'Vibration_sensor_3', 'Vibration_sensor_4']\n",
    "    rows = [\"Mean\", \"Standard Deviation\", \"Min\", \"Max\"]\n",
    "    #Turn around so we can process numbers as rows and exclude Status\n",
    "    data = data.transpose()\n",
    "    data = data[1:]\n",
    "    data = data.astype(float)\n",
    "    for col in data:\n",
    "        #Create tuple for each property (e.g. Power_range_sensor_1)\n",
    "        temp = (np.mean(col), np.std(col), np.amin(col), np.amax(col))\n",
    "        summary.append(temp)\n",
    "    #Create table\n",
    "    dataFrame = pandas.DataFrame(summary, columns=rows, index=cols)\n",
    "    print(dataFrame)\n",
    "    #Normally I would use Mean/Std/Min/Max as y axis labels but in this case the table would be too wide\n",
    "    #So .transpose() would make it more difficult to read\n",
    "    \n",
    "def genBoxPlot(data):\n",
    "    #Get the desired feature against the state, then zip into tuples\n",
    "    joined = list(zip(data[:,0], data[:,9]))\n",
    "    #Convert to np for np functionality\n",
    "    joined = np.asarray(joined)\n",
    "    #Find indices where the states are either normal, or abnormal and seperate them into different arrays so that we can do\n",
    "    #different subplots broken down by state\n",
    "    index = np.where(joined[0:,] == \"Normal\")[0]\n",
    "    normals = joined[index][:,1]\n",
    "    index = np.where(joined[0:,] == \"Abnormal\")[0]\n",
    "    abnormals = joined[index][:,1]\n",
    "    #\n",
    "    normals = normals.astype(float)\n",
    "    abnormals = abnormals.astype(float)\n",
    "    #Set plot properties\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.set_title('Normal and Abnormal state against Vibration Sensor 1')\n",
    "    ax.set_ylabel(\"Vibration Sensor 1\")\n",
    "    ax.set_xlabel(\"State\")\n",
    "    #ax.set_xticklabels([\"Normal\", \"Abnormal\"])\n",
    "    ax.boxplot([normals, abnormals], labels=[\"Normal\", \"Abnormal\"])\n",
    "    plt.show();\n",
    "    \n",
    "def genDensityPlot(data):\n",
    "    #Get the desired feature against the state, then zip into tuples\n",
    "    joined = list(zip(data[:,0], data[:,10]))\n",
    "    #Convert to np for np functionality\n",
    "    joined = np.asarray(joined)\n",
    "    #Find indices where the states are either normal, or abnormal and seperate them into different arrays so that we can do\n",
    "    #different subplots broken down by state\n",
    "    index = np.where(joined[0:,] == \"Normal\")[0]\n",
    "    normals = joined[index][:,1]\n",
    "    index = np.where(joined[0:,] == \"Abnormal\")[0]\n",
    "    abnormals = joined[index][:,1]\n",
    "    normals = normals.astype(float)\n",
    "    abnormals = abnormals.astype(float)\n",
    "\n",
    "    sns.kdeplot(normals, color=\"green\", shade=True, legend=True, label=\"Normal\")\n",
    "    sns.kdeplot(abnormals, color=\"red\", shade=True, legend=True, label=\"Abnormal\")\n",
    "    plt.legend()\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.xlabel(\"Vibration Sensor 2\")\n",
    "    plt.title(\"Density of values measured by Vibration Sensor 2 by state\")\n",
    "    plt.show();\n",
    "    \n",
    "#ANN\n",
    "# - 2 hidden layers\n",
    "# - Sigmoid function\n",
    "# - Hidden layer neurons: 500\n",
    "# - 90/10 train and test\n",
    "# - \n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, data, y, neurons, hidden, rate):\n",
    "        self.input = data\n",
    "        self.y = y\n",
    "        self.output = np.zeros(y.shape)\n",
    "        self.layers = hidden\n",
    "        self.neurons = neurons\n",
    "        self.learning_rate = rate\n",
    "        #self.weights_to_hidden = np.random.rand(self.neurons, self.input.shape[1])\n",
    "        #self.weights = self.generateWeightArray()\n",
    "        #self.weights_to_output = np.random.rand(self.neurons,1)\n",
    "        self.weights_to_hidden = np.random.rand(self.input.shape[1], self.neurons)\n",
    "        self.weights = self.generateWeightArray()\n",
    "        self.weights_to_output = np.random.rand(self.neurons,self.input.shape[0])\n",
    "    \n",
    "    #Generate a matrix with h+1 weight matrices, where h is the number of hidden layers (+1 for output)\n",
    "    def generateWeightArray(self):\n",
    "        weightarr = []\n",
    "        #Last weight array is for inbetween hidden and output layer\n",
    "        for i in range(self.layers):\n",
    "            weightarr.append(self.generateWeightMatrix())\n",
    "        return np.asarray(weightarr)\n",
    "    \n",
    "    #Generate a matrix with n columns and m rows, where n is the number of features and m is the number of neurons\n",
    "    #in the layer\n",
    "    def generateWeightMatrix(self):\n",
    "        return np.random.rand(self.neurons, self.neurons)\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def dsigmoid(self, x):\n",
    "        return self.sigmoid(x)*(1-self.sigmoid(x))\n",
    "    \n",
    "    def softmax(self,x):\n",
    "        return np.exp(x)/np.sum(np.exp(x))\n",
    "    \n",
    "    def train(self, epoch):\n",
    "        start=datetime.now()\n",
    "        iters = 0\n",
    "        while iters < epoch:\n",
    "            #2 hidden layers, then hidden -> output layer\n",
    "            hidden_matrices = []\n",
    "\n",
    "            #Input -> First hidden layer matrix\n",
    "            to_hidden = np.dot(self.input, self.weights_to_hidden)\n",
    "            hidden_in = self.sigmoid(to_hidden)\n",
    "            #Out\n",
    "            #Now process hidden layers\n",
    "            #print(\"Going into hidden layer:\")\n",
    "            #print(hidden_in)\n",
    "            for i in range(self.layers):\n",
    "                #Calculate whats in the hidden layers\n",
    "                in_hidden = 0\n",
    "                if len(hidden_matrices) == 0:\n",
    "                    in_hidden = self.sigmoid(np.dot(hidden_in, self.weights[i]))\n",
    "                else:\n",
    "                    in_hidden = self.sigmoid(np.dot(hidden_matrices[i-1], self.weights[i]))\n",
    "                hidden_matrices.append(in_hidden)\n",
    "                #print(\"After \",str(i+1), \" hidden layer:\")\n",
    "                #print(in_hidden)\n",
    "\n",
    "            #print(\"Output\")\n",
    "            out = self.sigmoid(np.dot(hidden_matrices[-1], self.weights_to_output))\n",
    "            if(iters == epoch-1):\n",
    "                print(\"Training ended after \", str(iters) ,\" iterations. Last output:\")\n",
    "                print(out)\n",
    "\n",
    "            #Backpropagate\n",
    "            #Then, get error between real and predicted\n",
    "            diff = self.y - out\n",
    "            delta_vector = self.weights_to_output* diff\n",
    "            #print(delta_vector)\n",
    "            hidden_deltas = []\n",
    "            #Lets do weights -> last layer first\n",
    "            result = np.dot(self.weights[-1], delta_vector)\n",
    "            #print(\"deltas to last layer\")\n",
    "            #print(result)\n",
    "\n",
    "            hidden_deltas.append(result)\n",
    "            #Then we work out delta for each one in the next hidden layers by dotting the weights against the previous delta\n",
    "            for i in range(self.layers):\n",
    "                #print(\"Delta for hidden layer \" , str(i))\n",
    "                result = np.dot(hidden_deltas[0 + i].transpose(), self.weights[self.layers - 1 - i]).transpose()\n",
    "                #   print(result)\n",
    "                hidden_deltas.append(result)\n",
    "            #Modify weights\n",
    "            # w' = w + learning_rate*hidden_deltas (for current hidden) * dsigmoid * input\n",
    "            new_input_weights = self.weights_to_hidden + self.learning_rate*self.dsigmoid(to_hidden)*np.dot(self.input.transpose(), hidden_deltas[-1].transpose())\n",
    "            self.weights_to_hidden = new_input_weights\n",
    "            #First weights updated!\n",
    "            #Now move hidden -> hidden -> output\n",
    "            for i in range(self.layers):\n",
    "                new_weights = self.weights[i] + self.learning_rate*(hidden_matrices[i]*(1-hidden_matrices[i]))*np.dot(hidden_matrices[i], hidden_deltas[i])\n",
    "                self.weights[i] = new_weights\n",
    "\n",
    "            #Now update hidden->output\n",
    "            #delta_vector -> delta for last one \n",
    "            #self.weights_to_output\n",
    "            #dsigmoid arg = out -> (out*(1-out)) <- dsigmoid\n",
    "            #hidden_matrices[-1] -> last hidden layer output\n",
    "            new_weights_to_output = self.weights_to_output + self.learning_rate*(out*(1-out))*np.dot(hidden_matrices[-1], delta_vector)\n",
    "            self.weights_to_output = new_weights_to_output\n",
    "            iters += 1\n",
    "        print(\"Finished in \",datetime.now()-start)\n",
    "        \n",
    "    def run(self, inarr, yarr):\n",
    "        #Input -> First hidden layer matrix\n",
    "        hidden_matrices = []\n",
    "        to_hidden = np.dot(inarr, self.weights_to_hidden)\n",
    "        hidden_in = self.sigmoid(to_hidden)\n",
    "        #Out\n",
    "        #Now process hidden layers\n",
    "        #print(\"Going into hidden layer:\")\n",
    "        #print(hidden_in)\n",
    "        for i in range(self.layers):\n",
    "            #Calculate whats in the hidden layers\n",
    "            in_hidden = 0\n",
    "            if len(hidden_matrices) == 0:\n",
    "                in_hidden = self.sigmoid(np.dot(hidden_in, self.weights[i]))\n",
    "            else:\n",
    "                in_hidden = self.sigmoid(np.dot(hidden_matrices[i-1], self.weights[i]))\n",
    "            hidden_matrices.append(in_hidden)\n",
    "            #print(\"After \",str(i+1), \" hidden layer:\")\n",
    "            #print(in_hidden)\n",
    "\n",
    "        #print(\"Output\")\n",
    "        out = self.sigmoid(np.dot(hidden_matrices[-1], self.weights_to_output))\n",
    "        print(\"Predicted for this input\")\n",
    "        print(out)\n",
    "        print(\"Real output\")\n",
    "        print(yarr)\n",
    "    \n",
    "'''\n",
    "data = read_coords(\"ML2_dataset.csv\")\n",
    "data = np.asarray(data) \n",
    "summarise(data)\n",
    "#Normalise dataset between 0 and 1\n",
    "normalised = normalise(data)\n",
    "#summarise(normalised)\n",
    "genBoxPlot(normalised)\n",
    "genDensityPlot(normalised)\n",
    "'''\n",
    "\n",
    "#net = NeuralNetwork(np.array([[1,2,3,4],[3,5,1,2],[5,6,7,8]]), np.array([1,0,1]), 5, 2, 0.3)\n",
    "net = NeuralNetwork(np.array([[1,2,3,4]]), np.array([1]), 15, 2, 0.3)\n",
    "#net.run()\n",
    "net.train(300)\n",
    "print(\"Running prediction on input array\")\n",
    "net.run(np.array([[10,25,32,49]]), np.array([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
