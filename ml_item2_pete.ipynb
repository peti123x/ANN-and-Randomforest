{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This set has a dimension of  (996, 13)\n",
      "                           Mean  Standard Deviation       Min        Max\n",
      "Power_range_sensor_1   4.999574            2.763467  0.008200  12.129800\n",
      "Power_range_sensor_2   6.379273            2.311408  0.040300  11.928400\n",
      "Power_range_sensor_3   9.228112            2.530901  2.583966  15.759900\n",
      "Power_range_sensor_4   7.355272            4.352591  0.062300  17.235858\n",
      "Pressure_sensor_1     14.199127           11.674180  0.024800  67.979400\n",
      "Pressure_sensor_2      3.077958            2.125023  0.008262  10.242738\n",
      "Pressure_sensor_3      5.749234            2.524867  0.001224  12.647500\n",
      "Pressure_sensor_4      4.997002            4.163398  0.005800  16.555620\n",
      "Vibration_sensor_1     8.164563            6.170162  0.000000  36.186438\n",
      "Vibration_sensor_2    10.001593            7.332549  0.018500  34.867600\n",
      "Vibration_sensor_3    15.187982           12.153519  0.064600  53.238400\n",
      "Vibration_sensor_4     9.933591            7.278727  0.009200  43.231400\n",
      "Epoch 1/1\n",
      "896/896 [==============================] - 0s 320us/step - loss: 0.6864 - accuracy: 0.5692\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x225e87a5b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy:0.51\n",
      "[0.6863565301895141, 0.5099999904632568]\n",
      "Performing 10-fold CV with 50 neurons...\n",
      "Training ...\n",
      "CV on test set at index 0 has 0.6600000262260437 accuracy\n",
      "CV on test set at index 1 has 0.6899999976158142 accuracy\n",
      "CV on test set at index 2 has 0.6700000166893005 accuracy\n",
      "CV on test set at index 3 has 0.7699999809265137 accuracy\n",
      "CV on test set at index 4 has 0.7200000286102295 accuracy\n",
      "CV on test set at index 5 has 0.7599999904632568 accuracy\n",
      "CV on test set at index 6 has 0.6969696879386902 accuracy\n",
      "CV on test set at index 7 has 0.6363636255264282 accuracy\n",
      "CV on test set at index 8 has 0.6666666865348816 accuracy\n",
      "CV on test set at index 9 has 0.6161616444587708 accuracy\n",
      "Mean accuracy is 0.6886161684989929\n",
      "Training and evaluating done.\n",
      "Performing 10-fold CV with 500 neurons...\n",
      "Training ...\n",
      "CV on test set at index 0 has 0.6399999856948853 accuracy\n",
      "CV on test set at index 1 has 0.7099999785423279 accuracy\n",
      "CV on test set at index 2 has 0.6899999976158142 accuracy\n",
      "CV on test set at index 3 has 0.7599999904632568 accuracy\n",
      "CV on test set at index 4 has 0.6600000262260437 accuracy\n",
      "CV on test set at index 5 has 0.800000011920929 accuracy\n",
      "CV on test set at index 6 has 0.7171717286109924 accuracy\n",
      "CV on test set at index 7 has 0.6464646458625793 accuracy\n",
      "CV on test set at index 8 has 0.5454545617103577 accuracy\n",
      "CV on test set at index 9 has 0.6060606241226196 accuracy\n",
      "Mean accuracy is 0.6775151550769806\n",
      "Training and evaluating done.\n",
      "Performing 10-fold CV with 1000 neurons...\n",
      "Training ...\n",
      "CV on test set at index 0 has 0.6499999761581421 accuracy\n",
      "CV on test set at index 1 has 0.6899999976158142 accuracy\n",
      "CV on test set at index 2 has 0.7200000286102295 accuracy\n",
      "CV on test set at index 3 has 0.75 accuracy\n",
      "CV on test set at index 4 has 0.6700000166893005 accuracy\n",
      "CV on test set at index 5 has 0.800000011920929 accuracy\n",
      "CV on test set at index 6 has 0.7373737096786499 accuracy\n",
      "CV on test set at index 7 has 0.6262626051902771 accuracy\n",
      "CV on test set at index 8 has 0.6161616444587708 accuracy\n",
      "CV on test set at index 9 has 0.6464646458625793 accuracy\n",
      "Mean accuracy is 0.6906262636184692\n",
      "Training and evaluating done.\n",
      "Assessment finished.\n",
      "Mean accuracy: 0.6886161684989929 for neurons = 50\n",
      "Mean accuracy: 0.6775151550769806 for neurons = 500\n",
      "Mean accuracy: 0.6906262636184692 for neurons = 1000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt \n",
    "import pandas\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn import ensemble\n",
    "\n",
    "#Read coordinate csv. Col 1 is x coords and Col2 is y coords. \n",
    "def read_coords(filename):     \n",
    "    myFile = open(filename) \n",
    "    row =0 \n",
    "    coords =[] \n",
    "    for line in myFile:\n",
    "        #skip first line as it contains labels\n",
    "        if row > 0:\n",
    "            coords.append(line.rstrip().split(\",\")[:])\n",
    "        row = row+1\n",
    "        #coords[row] = line.rstrip().split(\",\")[:] \n",
    "    myFile.close()\n",
    "    return coords\n",
    "\n",
    "def normalise(data):\n",
    "    #Transpose, take out labels and convert remaining data to float\n",
    "    data = data.transpose()\n",
    "    label = data[0]\n",
    "    data = data[1:]\n",
    "    data = data.astype(float)\n",
    "    #Enumerate through each col then each point in all\n",
    "    #Do z = (xi - min(x))/(max(x)-min(x)) to normalise where x marks the set of numbers\n",
    "    for j, col in enumerate(data):\n",
    "        #Get min and max to be able to normalise\n",
    "        cMax = np.amax(col)\n",
    "        cMin = np.amin(col)\n",
    "        for i, x in enumerate(col):\n",
    "            norm = (x - cMin)/(cMax - cMin)\n",
    "            #Write back\n",
    "            data[j][i] = norm\n",
    "    #Construct mutated data into original array with labels that we do by\n",
    "    #creating new list, adding labels and the dataset, converting to np array then transposing back to original dim\n",
    "    newData = []\n",
    "    newData.append(label)\n",
    "    newData[1:] = data\n",
    "    newData = np.asarray(newData)\n",
    "    newData = newData.transpose()\n",
    "    return newData\n",
    "\n",
    "def summarise(data):\n",
    "    print(\"This set has a dimension of \" , data.shape)\n",
    "    #This will contain a series of tuples that charectarise each row\n",
    "    summary = []\n",
    "    cols = ['Power_range_sensor_1', 'Power_range_sensor_2', 'Power_range_sensor_3', 'Power_range_sensor_4', 'Pressure_sensor_1', 'Pressure_sensor_2','Pressure_sensor_3', 'Pressure_sensor_4', 'Vibration_sensor_1', 'Vibration_sensor_2', 'Vibration_sensor_3', 'Vibration_sensor_4']\n",
    "    rows = [\"Mean\", \"Standard Deviation\", \"Min\", \"Max\"]\n",
    "    #Turn around so we can process numbers as rows and exclude Status\n",
    "    data = data.transpose()\n",
    "    data = data[1:]\n",
    "    data = data.astype(float)\n",
    "    for col in data:\n",
    "        #Create tuple for each property (e.g. Power_range_sensor_1)\n",
    "        temp = (np.mean(col), np.std(col), np.amin(col), np.amax(col))\n",
    "        summary.append(temp)\n",
    "    #Create table\n",
    "    dataFrame = pandas.DataFrame(summary, columns=rows, index=cols)\n",
    "    print(dataFrame)\n",
    "    #Normally I would use Mean/Std/Min/Max as y axis labels but in this case the table would be too wide\n",
    "    #So .transpose() would make it more difficult to read\n",
    "    \n",
    "def genBoxPlot(data):\n",
    "    #Get the desired feature against the state, then zip into tuples\n",
    "    joined = list(zip(data[:,0], data[:,9]))\n",
    "    #Convert to np for np functionality\n",
    "    joined = np.asarray(joined)\n",
    "    #Find indices where the states are either normal, or abnormal and seperate them into different arrays so that we can do\n",
    "    #different subplots broken down by state\n",
    "    index = np.where(joined[0:,] == \"Normal\")[0]\n",
    "    normals = joined[index][:,1]\n",
    "    index = np.where(joined[0:,] == \"Abnormal\")[0]\n",
    "    abnormals = joined[index][:,1]\n",
    "    #\n",
    "    normals = normals.astype(float)\n",
    "    abnormals = abnormals.astype(float)\n",
    "    #Set plot properties\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.set_title('Normal and Abnormal state against Vibration Sensor 1')\n",
    "    ax.set_ylabel(\"Vibration Sensor 1\")\n",
    "    ax.set_xlabel(\"State\")\n",
    "    #ax.set_xticklabels([\"Normal\", \"Abnormal\"])\n",
    "    ax.boxplot([normals, abnormals], labels=[\"Normal\", \"Abnormal\"])\n",
    "    plt.show();\n",
    "    \n",
    "def genDensityPlot(data):\n",
    "    #Get the desired feature against the state, then zip into tuples\n",
    "    joined = list(zip(data[:,0], data[:,10]))\n",
    "    #Convert to np for np functionality\n",
    "    joined = np.asarray(joined)\n",
    "    #Find indices where the states are either normal, or abnormal and seperate them into different arrays so that we can do\n",
    "    #different subplots broken down by state\n",
    "    index = np.where(joined[0:,] == \"Normal\")[0]\n",
    "    normals = joined[index][:,1]\n",
    "    index = np.where(joined[0:,] == \"Abnormal\")[0]\n",
    "    abnormals = joined[index][:,1]\n",
    "    normals = normals.astype(float)\n",
    "    abnormals = abnormals.astype(float)\n",
    "\n",
    "    sns.kdeplot(normals, color=\"green\", shade=True, legend=True, label=\"Normal\")\n",
    "    sns.kdeplot(abnormals, color=\"red\", shade=True, legend=True, label=\"Abnormal\")\n",
    "    plt.legend()\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.xlabel(\"Vibration Sensor 2\")\n",
    "    plt.title(\"Density of values measured by Vibration Sensor 2 by state\")\n",
    "    plt.show();\n",
    "    \n",
    "#ANN\n",
    "# - 2 hidden layers\n",
    "# - Sigmoid function\n",
    "# - Hidden layer neurons: 500\n",
    "# - 90/10 train and test\n",
    "# - \n",
    "#####ANN\n",
    "\n",
    "#Vary neurons from 50, 500, 1000 and do 10-fold CV on each\n",
    "#Report mean accuracy for each parameter (so mean accuracy for 50 neuron, 500 neurons, 1000 neurons)\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, data, trainProp, neurons, hiddenLayers, hiddenActiv, endActiv):\n",
    "        self.data = data\n",
    "        self.trainProp = trainProp\n",
    "        self.hidden = hiddenLayers\n",
    "        self.neurons = neurons\n",
    "        self.hidden_activation = hiddenActiv\n",
    "        self.end_activation = endActiv\n",
    "\n",
    "    def splitData(self, trainProp = 0.9):\n",
    "        #Shuffle\n",
    "        np.random.shuffle(self.data)\n",
    "        elems = len(data)\n",
    "        #Define set proportions we want\n",
    "        test_prop = 1 - trainProp\n",
    "\n",
    "        #Slice data array into two seperate arrays depending on proportions\n",
    "        #Train 0 to elems*proportion, test elems*proportion-1 to last\n",
    "        train_data = self.data[0:int(elems*trainProp)].transpose()\n",
    "        test_data = self.data[int(elems*trainProp)-1:-1].transpose()\n",
    "        #Split then transform string state to booleans\n",
    "        x_train = train_data[1:,].transpose()\n",
    "        y_train = train_data[0]\n",
    "        y_train[y_train==\"Normal\"] = 0\n",
    "        y_train[y_train==\"Abnormal\"] = 1\n",
    "\n",
    "        x_test = test_data[1:,].transpose()\n",
    "        y_test = test_data[0]\n",
    "        y_test[y_test==\"Normal\"] = 0\n",
    "        y_test[y_test==\"Abnormal\"] = 1\n",
    "\n",
    "        return [x_train,y_train], [x_test,y_test]\n",
    "    \n",
    "    def plotTrainAccuracy(self):\n",
    "        #Plot accuracy against epochs\n",
    "        plt.plot(self.history.history['accuracy'])\n",
    "        plt.ylabel(\"Model accuracy\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.title(\"Model training accuracy over epochs\")\n",
    "        plt.show()\n",
    "    \n",
    "    def train(self, ep = 1):\n",
    "        #Split data and save as class variables\n",
    "        self.train, self.test = self.splitData(self.trainProp)\n",
    "        #Init Keras, add layers\n",
    "        self.model = Sequential()\n",
    "        #First layer takes in 12 features and all rows\n",
    "        self.model.add(Dense(units=self.neurons, input_shape=(12,)))\n",
    "        #For all hidden layers, add\n",
    "        for i in range(self.hidden):\n",
    "            self.model.add(Dense(units=self.neurons, activation=self.hidden_activation, input_dim=(996,)))\n",
    "        #Add output layer, then compile and fit, then plot at the end of training\n",
    "        self.model.add(Dense(units=1, activation=self.end_activation))\n",
    "        self.model.compile(loss='binary_crossentropy',optimizer='sgd', metrics=['accuracy'])\n",
    "        self.history = self.model.fit(self.train[0], self.train[1], epochs=ep)\n",
    "        self.plotTrainAccuracy();\n",
    "    \n",
    "    def predict(self):\n",
    "        predicted = self.model.predict(self.test[0])\n",
    "        #Calc accuracy, between predicted and ground y\n",
    "        test_y = np.asarray(self.test[1]).transpose()\n",
    "        test_y = test_y.astype(float)\n",
    "        \n",
    "        corr = 0 \n",
    "        for i in range(len(test_y)):\n",
    "            if int(np.round(predicted[i][0])) == int(test_y[i]):\n",
    "                corr = corr + 1\n",
    "        print(\"Prediction accuracy:\" + str(float(corr/len(test_y))))\n",
    "        \n",
    "        score = self.model.evaluate(self.test[0], self.test[1], verbose=2)\n",
    "        print(score) #keras built in scoring\n",
    "    \n",
    "    #Partition data into n folds\n",
    "    def partition(self, chunks):\n",
    "        temp_data = self.data\n",
    "        temp_data[temp_data==\"Normal\"] = 0\n",
    "        temp_data[temp_data==\"Abnormal\"] = 1\n",
    "        partitions = np.array_split(temp_data, 10)\n",
    "        return partitions\n",
    "    \n",
    "    def makeTrainSet(self, parts, currTestIdx):\n",
    "        #Makes train set from all partitions that arent the delegated test set\n",
    "        concat = []\n",
    "        for i in range(0, len(parts)):\n",
    "            if i != currTestIdx:\n",
    "                for row in parts[i]:\n",
    "                    concat.append(row)\n",
    "        concat = np.asarray(concat)\n",
    "        return concat\n",
    "    \n",
    "    def nfold_cv(self, chunks, ep_each):\n",
    "        parts = self.partition(chunks)\n",
    "        testPartition = 0\n",
    "        #Mean accuracy\n",
    "        accuracies = []\n",
    "        #Lets assign first set as test first, then use other 9 as train\n",
    "        while testPartition < chunks:\n",
    "            #Build new model for each iteration\n",
    "            self.model = Sequential()\n",
    "            self.model.add(Dense(units=self.neurons, input_shape=(12,)))\n",
    "            for j in range(self.hidden):\n",
    "                self.model.add(Dense(units=self.neurons, activation=self.hidden_activation, input_dim=(996,)))\n",
    "            self.model.add(Dense(units=1, activation=self.end_activation))\n",
    "            self.model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "            #Then get the train set excluding the delegated test set\n",
    "            train = self.makeTrainSet(parts, testPartition)\n",
    "            train = train.transpose()\n",
    "            train_x = train[1:,].transpose()\n",
    "            train_y = train[0]\n",
    "            self.history = self.model.fit(train_x, train_y, epochs=ep_each, verbose=0)\n",
    "\n",
    "            #Network is trained, now predict on assigned test partition\n",
    "            test = parts[testPartition].transpose()\n",
    "            test_x = test[1:,].transpose()\n",
    "            test_y = test[0]\n",
    "            predicted = self.model.predict(test_x)\n",
    "            score = self.model.evaluate(test_x, test_y, verbose=2)\n",
    "            print(\"CV on test set at index \" + str(testPartition) + \" has \" + str(score[1]) + \" accuracy\")\n",
    "            accuracies.append(score[1])\n",
    "            #Assign next partition as test\n",
    "            testPartition = testPartition + 1\n",
    "        mean = sum(accuracies)/len(accuracies)\n",
    "        print(\"Mean accuracy is \" + str(mean))\n",
    "        return mean\n",
    "        \n",
    "    def assess_params(self, neuronarr, n, ep_each):\n",
    "        means = []\n",
    "        for elem in neuronarr:\n",
    "            self.neurons = elem\n",
    "            print(\"Performing \" + str(n) + \"-fold CV with \" + str(self.neurons) + \" neurons...\")\n",
    "            print(\"Training ...\")\n",
    "            mean = self.nfold_cv(n, ep_each)\n",
    "            means.append(mean)\n",
    "            print(\"Training and evaluating done.\")\n",
    "        print(\"Assessment finished.\")\n",
    "        for i in range(len(neuronarr)):\n",
    "            print(\"Mean accuracy: \" + str(means[i]) + \" for neurons = \" + str(neuronarr[i]))\n",
    "            \n",
    "        \n",
    "###Random Forest\n",
    "#Vary trees from 20, 500, 10000 and do 10-fold CV on each (with min samples = 5)\n",
    "#Report mean accuracy for each parameter (so mean accuracy for 20 trees, 500 trees, 10000 trees)\n",
    "class RandomForest():\n",
    "    def __init__(self, trees, min_samples, train, test):\n",
    "        #Random Forest should be taking in the same training and test data (same shuffle and length)\n",
    "        #so we can initialise it with data taken from ANN\n",
    "        self.trees = trees\n",
    "        self.min_samples_leaf = min_samples\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        \n",
    "    def train_model(self):\n",
    "        self.tree = ensemble.RandomForestClassifier(n_estimators = self.trees, criterion='entropy', min_samples_leaf=self.min_samples_leaf)\n",
    "        self.tree.fit(self.train[0], self.train[1])\n",
    "        \n",
    "    def predict(self):\n",
    "        #Predict, then measure accuracy\n",
    "        predicted = self.tree.predict(self.test[0])\n",
    "        accuracy = self.measure_accuracy(predicted)\n",
    "        print(\"Prediction accuracy:\" + str(accuracy))\n",
    "        return accuracy\n",
    "        \n",
    "    def measure_accuracy(self, predicted):\n",
    "        corr = 0\n",
    "        for i in range(len(predicted)):\n",
    "            if(int(predicted[i]) == int(test[1][i])):\n",
    "                corr = corr + 1\n",
    "        return float(corr/len(predicted))\n",
    "    \n",
    "    #This takes in an array of trees, and min samples at the leaf, trains a model each with these parameters\n",
    "    #and graphs accuracies for parameters\n",
    "    def measure_all_params(self, trees, min_at_leaf):\n",
    "        accuracies = {}\n",
    "        #For each minimum sample, train with array of trees one by one\n",
    "        for minim in min_at_leaf:\n",
    "            self.min_samples_leaf = minim\n",
    "            accuracies[minim] = []\n",
    "            for num in trees:\n",
    "                #Set trees, train, then predict and save accuracy\n",
    "                self.trees = num\n",
    "                self.train_model()\n",
    "                accuracy = self.predict()\n",
    "                accuracies[minim].append(accuracy)\n",
    "        #Plot\n",
    "        self.plot_accuracies(accuracies, trees)\n",
    "        \n",
    "    def plot_accuracies(self, accuracies, trees):\n",
    "        #Subplot\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(14, 4))\n",
    "        keyindex = 0\n",
    "        #Colours for each number of tree\n",
    "        cols = [\"#000000\", \"#ff0000\", \"#ff00ff\", \"#5ac18e\", \"#0000ff\"]\n",
    "        for key in accuracies.keys():\n",
    "            numbers = np.arange(1, len(trees)+1)\n",
    "            for i in range(len(trees)):\n",
    "                axs[keyindex].scatter(numbers[i], accuracies[key][i], label=str(trees[i])+\" trees\", color=cols[i])\n",
    "            axs[keyindex].set_xlabel(\"Point\")\n",
    "            axs[keyindex].set_ylabel(\"Accuracy\")\n",
    "            axs[keyindex].set_title(\"Accuracy against number of trees at \" + str(key) + \" samples at leaf\")\n",
    "            axs[keyindex].grid(True)\n",
    "            axs[keyindex].legend()\n",
    "            keyindex = keyindex + 1\n",
    "###Random Forest\n",
    "\n",
    "data = read_coords(\"ML2_dataset.csv\")\n",
    "data = np.asarray(data) \n",
    "summarise(data)\n",
    "#Normalise dataset between 0 and 1\n",
    "normalised = normalise(data)\n",
    "#summarise(normalised)\n",
    "#genBoxPlot(normalised)\n",
    "#genDensityPlot(normalised)\n",
    "\n",
    "net = NeuralNetwork(normalised, 0.9,500,2,'tanh','sigmoid')\n",
    "net.train(1)\n",
    "net.predict()\n",
    "#Section 4:\n",
    "net.assess_params([50, 500, 1000], 10, 30)\n",
    "\n",
    "#To use the same shuffled data, get them out of the ANN\n",
    "train = net.train\n",
    "test = net.test\n",
    "\n",
    "#forest = RandomForest(1000, 5, train, test)\n",
    "#forest.measure_all_params([10, 50, 100, 1000, 5000], [5, 50])\n",
    "\n",
    "#forest.train(train)\n",
    "#forest.predict(test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
